"""
–ü—Ä–æ—Å—Ç–æ–π —Ç–µ—Å—Ç —Å–∏—Å—Ç–µ–º—ã –ø–æ–Ω–∏–º–∞–Ω–∏—è –Ω–∞–º–µ—Ä–µ–Ω–∏–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π
–¢–µ—Å—Ç–∏—Ä—É–µ—Ç language normalization –±–µ–∑ —Å–ª–æ–∂–Ω—ã—Ö –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π
"""

import sys
from pathlib import Path

# Add backend directory to path
backend_path = Path(__file__).parent
sys.path.insert(0, str(backend_path))

from language_normalization import LanguageNormalizer, get_normalizer
from equivalence_engine import ExchangeEquivalence


class SimpleMatchingTester:
    """–ü—Ä–æ—Å—Ç–æ–π —Ç–µ—Å—Ç–µ—Ä —Å–∏—Å—Ç–µ–º—ã –ø–æ–Ω–∏–º–∞–Ω–∏—è –Ω–∞–º–µ—Ä–µ–Ω–∏–π"""

    def __init__(self):
        self.normalizer = get_normalizer()
        self.equivalence_engine = ExchangeEquivalence()

    def test_semantic_accuracy(self):
        """1.1 –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å"""
        print("\n" + "="*80)
        print("üéØ 1.1 –°–ï–ú–ê–ù–¢–ò–ß–ï–°–ö–ê–Ø –¢–û–ß–ù–û–°–¢–¨")
        print("="*80)

        test_cases = [
            # –ü–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–µ —Å–ª—É—á–∞–∏ (–¥–æ–ª–∂–Ω—ã –Ω–∞–π—Ç–∏—Å—å)
            ("–≤–µ–ª–æ—Å–∏–ø–µ–¥", "–±–∞–π–∫", 30000, 30000, "transport", "temporary", 7, 7, "‚úÖ –î–û–õ–ñ–ï–ù –ù–ê–ô–¢–ò: —Å–∏–Ω–æ–Ω–∏–º—ã"),
            ("iPhone", "–∞–π—Ñ–æ–Ω", 500000, 500000, "electronics", "permanent", None, None, "‚úÖ –î–û–õ–ñ–ï–ù –ù–ê–ô–¢–ò: —Ç—Ä–∞–Ω—Å–ª–∏—Ç–µ—Ä–∞—Ü–∏—è"),
            ("–Ω–æ—É—Ç–±—É–∫", "laptop", 400000, 400000, "electronics", "permanent", None, None, "‚úÖ –î–û–õ–ñ–ï–ù –ù–ê–ô–¢–ò: —Å–∏–Ω–æ–Ω–∏–º—ã"),

            # –û—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–µ —Å–ª—É—á–∞–∏ (–ù–ï –¥–æ–ª–∂–Ω—ã –Ω–∞–π—Ç–∏—Å—å)
            ("—Ä–µ–º–æ–Ω—Ç —Ç–µ–ª–µ—Ñ–æ–Ω–∞", "–ø—Ä–æ–¥–∞–∂–∞ —Ç–µ–ª–µ—Ñ–æ–Ω–∞", 5000, 500000, "services", "temporary", 1, None, "‚ùå –ù–ï –î–û–õ–ñ–ï–ù –ù–ê–ô–¢–ò: —Ä–∞–∑–Ω—ã–µ –Ω–∞–º–µ—Ä–µ–Ω–∏—è"),
            ("–ø—Ä–æ–∫–∞—Ç –≤–µ–ª–æ—Å–∏–ø–µ–¥–∞", "–ø–æ–∫—É–ø–∫–∞ –≤–µ–ª–æ—Å–∏–ø–µ–¥–∞", 1000, 50000, "transport", "temporary", 7, None, "‚ùå –ù–ï –î–û–õ–ñ–ï–ù –ù–ê–ô–¢–ò: –∞—Ä–µ–Ω–¥–∞ vs –ø–æ–∫—É–ø–∫–∞"),
        ]

        results = []
        for want_text, offer_text, want_price, offer_price, category, ex_type, want_days, offer_days, expected in test_cases:
            print(f"\nüìã –¢–µ—Å—Ç: '{want_text}' ‚Üî '{offer_text}'")

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º language similarity
            lang_score = self.normalizer.similarity_score(want_text, offer_text)
            print(f"  Language similarity: {lang_score:.3f}")

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º equivalence
            if ex_type == "permanent":
                equiv_result = self.equivalence_engine.calculate_permanent_score(want_price, offer_price)
            else:
                equiv_result = self.equivalence_engine.calculate_temporary_score(
                    want_price, want_days or 1, offer_price, offer_days or 1
                )

            print(f"  Equivalence score: {equiv_result.score:.3f} ({equiv_result.category.value})")

            # Combined score (70% equivalence + 30% language)
            combined_score = equiv_result.score * 0.7 + lang_score * 0.3
            print(f"  Combined score: {combined_score:.3f}")

            # –û—Ü–µ–Ω–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
            is_match = equiv_result.is_match and combined_score >= 0.70
            should_match = "‚úÖ –î–û–õ–ñ–ï–ù" in expected

            if should_match and is_match:
                status = "‚úÖ PASS"
            elif not should_match and not is_match:
                status = "‚úÖ PASS"
            else:
                status = "‚ùå FAIL"

            print(f"  Result: {status} | Expected: {expected}")
            print(f"  Match: {is_match} | Combined: {combined_score:.3f}")

            results.append({
                'test': f"{want_text} ‚Üî {offer_text}",
                'lang_score': lang_score,
                'equiv_score': equiv_result.score,
                'combined_score': combined_score,
                'is_match': is_match,
                'expected_match': should_match,
                'status': status
            })

        # –ò—Ç–æ–≥–∏
        passed = sum(1 for r in results if r['status'] == "‚úÖ PASS")
        total = len(results)
        print(f"\nüìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–π —Ç–æ—á–Ω–æ—Å—Ç–∏: {passed}/{total} ({passed/total*100:.1f}%)")

        return results

    def test_grammar_orthography(self):
        """1.2 –ì—Ä–∞–º–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –≤–∞—Ä–∏–∞—Ü–∏–∏ –∏ –æ—Ä—Ñ–æ–≥—Ä–∞—Ñ–∏—è"""
        print("\n" + "="*80)
        print("üìù 1.2 –ì–†–ê–ú–ú–ê–¢–ò–ß–ï–°–ö–ò–ï –í–ê–†–ò–ê–¶–ò–ò –ò –û–†–§–û–ì–†–ê–§–ò–Ø")
        print("="*80)

        test_cases = [
            # –ì—Ä–∞–º–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –≤–∞—Ä–∏–∞—Ü–∏–∏ (–¥–æ–ª–∂–Ω—ã –Ω–∞–π—Ç–∏—Å—å)
            ("–∏–≥—Ä–æ–≤–∞—è –ø—Ä–∏—Å—Ç–∞–≤–∫–∞", "–∏–≥—Ä–æ–≤—ã–µ –ø—Ä–∏—Å—Ç–∞–≤–∫–∏", 50000, 50000, "‚úÖ –î–û–õ–ñ–ï–ù –ù–ê–ô–¢–ò: —Ñ–æ—Ä–º—ã —á–∏—Å–ª–∞"),
            ("–≤–µ–ª–æ—Å–µ–ø–µ–¥", "–≤–µ–ª–æ—Å–∏–ø–µ–¥", 30000, 30000, "‚úÖ –î–û–õ–ñ–ï–ù –ù–ê–ô–¢–ò: –æ–ø–µ—á–∞—Ç–∫–∞"),
            ("—Å–¥–∞—Ç—å –∫–≤–∞—Ä—Ç–∏—Ä—É", "—Å–¥–∞—é –∫–≤–∞—Ä—Ç–∏—Ä—É", 15000, 15000, "‚úÖ –î–û–õ–ñ–ï–ù –ù–ê–ô–¢–ò: —Ñ–æ—Ä–º—ã –≥–ª–∞–≥–æ–ª–∞"),

            # –†–∞–∑–Ω—ã–µ –Ω–∞–º–µ—Ä–µ–Ω–∏—è (–ù–ï –¥–æ–ª–∂–Ω—ã –Ω–∞–π—Ç–∏—Å—å)
            ("—Å–¥–∞—Ç—å –∫–≤–∞—Ä—Ç–∏—Ä—É", "—Å–Ω—è—Ç—å –∫–≤–∞—Ä—Ç–∏—Ä—É", 15000, 15000, "‚ùå –ù–ï –î–û–õ–ñ–ï–ù –ù–ê–ô–¢–ò: —Ä–∞–∑–Ω—ã–µ –Ω–∞–º–µ—Ä–µ–Ω–∏—è"),
        ]

        results = []
        for text1, text2, price1, price2, expected in test_cases:
            print(f"\nüìã –¢–µ—Å—Ç: '{text1}' ‚Üî '{text2}'")

            lang_score = self.normalizer.similarity_score(text1, text2)
            print(f"  Language similarity: {lang_score:.3f}")

            # –î–ª—è –≥—Ä–∞–º–º–∞—Ç–∏—á–µ—Å–∫–∏—Ö —Ç–µ—Å—Ç–æ–≤ –∏—Å–ø–æ–ª—å–∑—É–µ–º permanent (—É–ø—Ä–æ—â–∞–µ–º)
            equiv_result = self.equivalence_engine.calculate_permanent_score(price1, price2)
            combined_score = equiv_result.score * 0.7 + lang_score * 0.3

            # Use same logic as in matching engine
            is_match = equiv_result.is_match and combined_score >= 0.70
            should_match = "‚úÖ –î–û–õ–ñ–ï–ù" in expected

            if should_match and is_match:
                status = "‚úÖ PASS"
            elif not should_match and not is_match:
                status = "‚úÖ PASS"
            else:
                status = "‚ùå FAIL"

            print(f"  Result: {status} | Expected: {expected}")
            print(f"  Combined score: {combined_score:.3f}")

            results.append({
                'test': f"{text1} ‚Üî {text2}",
                'lang_score': lang_score,
                'combined_score': combined_score,
                'is_match': is_match,
                'expected_match': should_match,
                'status': status
            })

        passed = sum(1 for r in results if r['status'] == "‚úÖ PASS")
        total = len(results)
        print(f"\nüìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –≥—Ä–∞–º–º–∞—Ç–∏–∫–∏/–æ—Ä—Ñ–æ–≥—Ä–∞—Ñ–∏–∏: {passed}/{total} ({passed/total*100:.1f}%)")

        return results

    def test_category_compatibility(self):
        """1.3 –ö–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω–∞—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å"""
        print("\n" + "="*80)
        print("üîÑ 1.3 –ö–ê–¢–ï–ì–û–†–ò–ê–õ–¨–ù–ê–Ø –°–û–í–ú–ï–°–¢–ò–ú–û–°–¢–¨")
        print("="*80)

        test_cases = [
            # –ú–µ–∂–∫–∞—Ç–µ–≥–æ—Ä–∏–π–Ω—ã–µ —Ç–µ—Å—Ç—ã (—Ç–µ–ø–µ—Ä—å –¥–æ–ª–∂–Ω—ã –ø—Ä–æ—Ö–æ–¥–∏—Ç—å —Å –Ω–æ–≤—ã–º–∏ –ø–æ—Ä–æ–≥–∞–º–∏)
            ("–≥–∏—Ç–∞—Ä–∞", "–∫—É—Ä—Å—ã –∞–Ω–≥–ª–∏–π—Å–∫–æ–≥–æ", 25000, 15000, "temporary", 10, 20, "‚úÖ –î–û–õ–ñ–ï–ù –ù–ê–ô–¢–ò: —Ä–∞–∑–Ω—ã–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏, —É—Å–ª—É–≥–∏ (—Å–Ω–∏–∂–µ–Ω–Ω—ã–π –ø–æ—Ä–æ–≥)"),
            ("–∫–≤–∞—Ä—Ç–∏—Ä–∞ –Ω–∞ —Å—É—Ç–∫–∏", "–∞—Ä–µ–Ω–¥–∞ –∞–≤—Ç–æ", 20000, 8000, "temporary", 1, 1, "‚úÖ –î–û–õ–ñ–ï–ù –ù–ê–ô–¢–ò: –∞—Ä–µ–Ω–¥–∞ ‚Üî –∞—Ä–µ–Ω–¥–∞ (—Å–∏–Ω–æ–Ω–∏–º—ã)"),
            ("—Ä–∞–±–æ—Ç–∞ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Å—Ç–∞", "—É—Å–ª—É–≥–∏ –¥–∏–∑–∞–π–Ω–µ—Ä–∞", 50000, 30000, "temporary", 30, 15, "‚úÖ –î–û–õ–ñ–ï–ù –ù–ê–ô–¢–ò: —É—Å–ª—É–≥–∏ ‚Üî —É—Å–ª—É–≥–∏ (—Å–∏–Ω–æ–Ω–∏–º—ã)"),
        ]

        results = []
        for want_text, offer_text, want_price, offer_price, ex_type, want_days, offer_days, expected in test_cases:
            print(f"\nüìã –¢–µ—Å—Ç: '{want_text}' ‚Üî '{offer_text}'")

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º language similarity
            lang_score = self.normalizer.similarity_score(want_text, offer_text)
            print(f"  Language similarity: {lang_score:.3f}")

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º equivalence with cross-category tolerance
            is_cross_category = True  # All these tests are cross-category by design
            equiv_result = self.equivalence_engine.calculate_temporary_score(
                want_price, want_days, offer_price, offer_days,
                tolerance=0.5 if is_cross_category else None
            )

            combined_score = equiv_result.score * 0.7 + lang_score * 0.3

            print(f"  Equivalence score: {equiv_result.score:.3f}")
            print(f"  Combined score: {combined_score:.3f}")

            # Use dynamic thresholds like in matching engine
            equivalence_threshold = 0.30 if is_cross_category else self.equivalence_engine.config.MIN_MATCH_SCORE
            threshold = 0.20 if is_cross_category else 0.70
            result_is_match = equiv_result.score >= equivalence_threshold

            is_match = result_is_match and combined_score >= threshold
            should_match = "‚úÖ –î–û–õ–ñ–ï–ù" in expected

            if should_match and is_match:
                status = "‚úÖ PASS"
            elif not should_match and not is_match:
                status = "‚úÖ PASS"
            else:
                status = "‚ùå FAIL"

            print(f"  Result: {status} | Expected: {expected}")

            results.append({
                'test': f"{want_text} ‚Üî {offer_text}",
                'lang_score': lang_score,
                'equiv_score': equiv_result.score,
                'combined_score': combined_score,
                'is_match': is_match,
                'expected_match': should_match,
                'status': status
            })

        passed = sum(1 for r in results if r['status'] == "‚úÖ PASS")
        total = len(results)
        print(f"\nüìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏: {passed}/{total} ({passed/total*100:.1f}%)")

        return results

    def test_false_positives(self):
        """1.8 –û—Ç—Å–µ—á–µ–Ω–∏–µ –ª–æ–∂–Ω—ã—Ö —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π"""
        print("\n" + "="*80)
        print("üö´ 1.8 –û–¢–°–ï–ß–ï–ù–ò–ï –õ–û–ñ–ù–´–• –°–û–í–ü–ê–î–ï–ù–ò–ô")
        print("="*80)

        test_cases = [
            # –õ–æ–∂–Ω—ã–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è (–ù–ï –¥–æ–ª–∂–Ω—ã –Ω–∞–π—Ç–∏—Å—å)
            ("–∫—É—Ä—Å—ã –¥–∏–∑–∞–π–Ω–∞", "—Ä–∞–±–æ—Ç–∞ –¥–∏–∑–∞–π–Ω–µ—Ä–æ–º", 20000, 50000, "‚ùå –ù–ï –î–û–õ–ñ–ï–ù –ù–ê–ô–¢–ò: —Ä–∞–∑–Ω—ã–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç—ã"),
            ("–ø—Ä–æ–¥–∞–∂–∞ –∞–≤—Ç–æ", "–∞—Ä–µ–Ω–¥–∞ –∞–≤—Ç–æ", 1000000, 15000, "‚ùå –ù–ï –î–û–õ–ñ–ï–ù –ù–ê–ô–¢–ò: –ø—Ä–æ–¥–∞–∂–∞ vs –∞—Ä–µ–Ω–¥–∞"),
            ("—Å–Ω—è—Ç—å –∂–∏–ª—å—ë", "—Å–¥–∞—é –∂–∏–ª—å—ë", 25000, 25000, "‚úÖ –î–û–õ–ñ–ï–ù –ù–ê–ô–¢–ò: —Å–∏–º–º–µ—Ç—Ä–∏—á–Ω—ã–µ –Ω–∞–º–µ—Ä–µ–Ω–∏—è"),
        ]

        results = []
        for text1, text2, price1, price2, expected in test_cases:
            print(f"\nüìã –¢–µ—Å—Ç: '{text1}' ‚Üî '{text2}'")

            lang_score = self.normalizer.similarity_score(text1, text2)
            equiv_result = self.equivalence_engine.calculate_permanent_score(price1, price2)
            combined_score = equiv_result.score * 0.7 + lang_score * 0.3

            is_match = equiv_result.is_match and combined_score >= 0.70
            should_match = "‚úÖ –î–û–õ–ñ–ï–ù" in expected

            if should_match and is_match:
                status = "‚úÖ PASS"
            elif not should_match and not is_match:
                status = "‚úÖ PASS"
            else:
                status = "‚ùå FAIL"

            print(f"  Language: {lang_score:.3f} | Combined: {combined_score:.3f}")
            print(f"  Result: {status} | Expected: {expected}")

            results.append({
                'test': f"{text1} ‚Üî {text2}",
                'lang_score': lang_score,
                'combined_score': combined_score,
                'is_match': is_match,
                'expected_match': should_match,
                'status': status
            })

        passed = sum(1 for r in results if r['status'] == "‚úÖ PASS")
        total = len(results)
        print(f"\nüìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ—Ç—Å–µ—á–µ–Ω–∏—è –ª–æ–∂–Ω—ã—Ö —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π: {passed}/{total} ({passed/total*100:.1f}%)")

        return results

    def run_all_tests(self):
        """–ó–∞–ø—É—Å—Ç–∏—Ç—å –≤—Å–µ —Ç–µ—Å—Ç—ã"""
        print("üß™ –ó–ê–ü–£–°–ö –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–Ø –°–ò–°–¢–ï–ú–´ –ü–û–ù–ò–ú–ê–ù–ò–Ø –ù–ê–ú–ï–†–ï–ù–ò–ô")
        print("="*80)

        all_results = []

        # 1. –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å
        semantic_results = self.test_semantic_accuracy()
        all_results.extend(semantic_results)

        # 2. –ì—Ä–∞–º–º–∞—Ç–∏–∫–∞ –∏ –æ—Ä—Ñ–æ–≥—Ä–∞—Ñ–∏—è
        grammar_results = self.test_grammar_orthography()
        all_results.extend(grammar_results)

        # 3. –ö–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω–∞—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å
        category_results = self.test_category_compatibility()
        all_results.extend(category_results)

        # 4. –û—Ç—Å–µ—á–µ–Ω–∏–µ –ª–æ–∂–Ω—ã—Ö —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π
        false_positive_results = self.test_false_positives()
        all_results.extend(false_positive_results)

        # –ò—Ç–æ–≥–æ–≤—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        print("\n" + "="*80)
        print("üìä –ò–¢–û–ì–û–í–´–ï –†–ï–ó–£–õ–¨–¢–ê–¢–´ –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–Ø")
        print("="*80)

        total_passed = sum(1 for r in all_results if r['status'] == "‚úÖ PASS")
        total_tests = len(all_results)

        print(f"–û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–µ—Å—Ç–æ–≤: {total_tests}")
        print(f"–ü—Ä–æ—à–ª–æ —É—Å–ø–µ—à–Ω–æ: {total_passed}")
        print(f"–£—Å–ø–µ—à–Ω–æ—Å—Ç—å: {total_passed/total_tests*100:.1f}%")

        # –î–µ—Ç–∞–ª–∏–∑–∞—Ü–∏—è –ø–æ —Ç–∏–ø–∞–º
        semantic_passed = sum(1 for r in semantic_results if r['status'] == "‚úÖ PASS")
        grammar_passed = sum(1 for r in grammar_results if r['status'] == "‚úÖ PASS")
        category_passed = sum(1 for r in category_results if r['status'] == "‚úÖ PASS")
        false_positive_passed = sum(1 for r in false_positive_results if r['status'] == "‚úÖ PASS")

        print("\n–ü–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º:")
        print(f"  –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å: {semantic_passed}/{len(semantic_results)}")
        print(f"  –ì—Ä–∞–º–º–∞—Ç–∏–∫–∞/–æ—Ä—Ñ–æ–≥—Ä–∞—Ñ–∏—è: {grammar_passed}/{len(grammar_results)}")
        print(f"  –ö–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω–∞—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å: {category_passed}/{len(category_results)}")
        print(f"  –û—Ç—Å–µ—á–µ–Ω–∏–µ –ª–æ–∂–Ω—ã—Ö —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π: {false_positive_passed}/{len(false_positive_results)}")

        return all_results


if __name__ == "__main__":
    tester = SimpleMatchingTester()
    results = tester.run_all_tests()
