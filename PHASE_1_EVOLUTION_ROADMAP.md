# üß≠ –≠—Ç–∞–ø 1 ‚Äî –£—Å–∏–ª–µ–Ω–∏–µ rule-based —è–¥—Ä–∞

## üìã –û–±–∑–æ—Ä

**–¶–µ–ª—å:** –ü–æ–≤—ã—Å–∏—Ç—å –∫–∞—á–µ—Å—Ç–≤–æ –∏ —É—Å—Ç–æ–π—á–∏–≤–æ—Å—Ç—å matching –±–µ–∑ —Å–ª–æ–∂–Ω—ã—Ö ML-–º–æ–¥–µ–ª–µ–π.

**–°—Ä–æ–∫:** 1‚Äì2 –Ω–µ–¥–µ–ª–∏

**–í—ã–≥–æ–¥–∞:** –°—Ä–∞–∑—É —É–ª—É—á—à–∞–µ—Ç —Ç–æ—á–Ω–æ—Å—Ç—å –∏ —Å–Ω–∏–∂–∞–µ—Ç –ª–æ–∂–Ω—ã–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è.

---

## ‚úÖ –†–µ–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã

### 1Ô∏è‚É£ –ö–∞—Ç–µ–≥–æ—Ä–∏–π–Ω—ã–µ —Ñ–∏–ª—å—Ç—Ä—ã (`backend/matching/rule_based.py`)

**–ü—Ä–æ–±–ª–µ–º–∞:** –°–∏—Å—Ç–µ–º–∞ –Ω–µ —Ä–∞–∑–ª–∏—á–∞–µ—Ç –∫–∞—Ç–µ–≥–æ—Ä–∏–∏, "–∞–π—Ñ–æ–Ω" –º–æ–∂–µ—Ç –º–∞—Ç—á–∏—Ç—å—Å—è —Å "—á–µ—Ö–ª–æ–º –¥–ª—è –∞–π—Ñ–æ–Ω–∞".

**–†–µ—à–µ–Ω–∏–µ:** –î–æ–±–∞–≤–ª–µ–Ω `CategoryFilter` —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –≤–µ—Å–æ–≤ –∫–∞—Ç–µ–≥–æ—Ä–∏–π.

**–ß—Ç–æ —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω–æ:**
- ‚úÖ –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –∫–∞—Ç–µ–≥–æ—Ä–∏–π —Å –∫–ª—é—á–µ–≤—ã–º–∏ —Ç–µ—Ä–º–∏–Ω–∞–º–∏ (`backend/data/category_weights.json`)
- ‚úÖ –§—É–Ω–∫—Ü–∏—è `get_category_weight()` ‚Äî –≤—ã—á–∏—Å–ª—è–µ—Ç –≤–µ—Å —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è –∫–∞—Ç–µ–≥–æ—Ä–∏–π (1.0 = —Å–æ–≤–ø–∞–¥–∞–µ—Ç, 0.1 = —Ä–∞–∑–Ω—ã–µ)
- ‚úÖ –§—É–Ω–∫—Ü–∏—è `filter_score()` ‚Äî –ø—Ä–∏–º–µ–Ω—è–µ—Ç –≤–µ—Å –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –∫ –∏—Ç–æ–≥–æ–≤–æ–º—É score
- ‚úÖ –§—É–Ω–∫—Ü–∏—è `is_valid_match()` ‚Äî –ø—Ä–æ–≤–µ—Ä—è–µ—Ç –≤–∞–ª–∏–¥–Ω–æ—Å—Ç—å –º–∞—Ç—á–∞ (–æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤—ã–≤–∞–µ—Ç —á–∞—Å—Ç–∏—á–Ω—ã–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è)

**–†–µ–∑—É–ª—å—Ç–∞—Ç:**
- "–∞–π—Ñ–æ–Ω" vs "–∞–π—Ñ–æ–Ω" ‚Üí weight = 1.0 (—Å–æ–≤–ø–∞–¥–∞–µ—Ç)
- "–∞–π—Ñ–æ–Ω" vs "—á–µ—Ö–æ–ª –¥–ª—è –∞–π—Ñ–æ–Ω–∞" ‚Üí –≤–µ—Å —Å–Ω–∏–∂–∞–µ—Ç—Å—è, score –ø–∞–¥–∞–µ—Ç (–Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –º–∞—Ç—á)
- "–≤–µ–ª–æ—Å–∏–ø–µ–¥" vs "–¥–∏–≤–∞–Ω" ‚Üí weight = 0.1 (—Ä–∞–∑–Ω—ã–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏)

**–¢–µ—Å—Ç—ã:** ‚úÖ `TestCategoryFilter` (6 —Ç–µ—Å—Ç–æ–≤)

---

### 2Ô∏è‚É£ –ú–æ—Ä—Ñ–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π –ª–µ–º–º–∞—Ç–∏–∑–∞—Ç–æ—Ä (`backend/matching/rule_based.py`)

**–ü—Ä–æ–±–ª–µ–º–∞:** "–ö—É–ø–ª—é –≤–µ–ª–æ—Å–∏–ø–µ–¥—ã" vs "–≤–µ–ª–æ—Å–∏–ø–µ–¥" –Ω–µ —Å–æ–≤–ø–∞–¥–∞—é—Ç –Ω–∞ —É—Ä–æ–≤–Ω–µ —Å–ª–æ–≤.

**–†–µ—à–µ–Ω–∏–µ:** –ò–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω–∞ `pymorphy2` –¥–ª—è –ª–µ–º–º–∞—Ç–∏–∑–∞—Ü–∏–∏.

**–ß—Ç–æ —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω–æ:**
- ‚úÖ `MorphologyProcessor` ‚Äî –æ–±—ë—Ä—Ç–∫–∞ –Ω–∞–¥ pymorphy2
- ‚úÖ –ú–µ—Ç–æ–¥ `lemmatize()` ‚Äî –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç —Å–ª–æ–≤–æ –≤ –ª–µ–º–º—É (–≤–µ–ª–æ—Å–∏–ø–µ–¥—ã ‚Üí –≤–µ–ª–æ—Å–∏–ø–µ–¥)
- ‚úÖ –ú–µ—Ç–æ–¥ `lemmatize_text()` ‚Äî –ª–µ–º–º–∞—Ç–∏–∑–∏—Ä—É–µ—Ç –≤–µ—Å—å —Ç–µ–∫—Å—Ç
- ‚úÖ –ú–µ—Ç–æ–¥ `get_pos()` ‚Äî –ø–æ–ª—É—á–∞–µ—Ç —á–∞—Å—Ç—å —Ä–µ—á–∏ —Å–ª–æ–≤–∞

**–†–µ–∑—É–ª—å—Ç–∞—Ç:**
- "–∫—É–ø–ª—é –≤–µ–ª–æ—Å–∏–ø–µ–¥—ã" ‚Üí "–∫—É–ø–∏—Ç—å –≤–µ–ª–æ—Å–∏–ø–µ–¥"
- "–≤–µ–ª–æ—Å–∏–ø–µ–¥—ã" ‚Üí "–≤–µ–ª–æ—Å–∏–ø–µ–¥"
- "–∫—É–ø–ª—é" ‚Üí "–∫—É–ø–∏—Ç—å"

**–£—Å—Ç–∞–Ω–æ–≤–∫–∞:**
```bash
pip install pymorphy2
```

**–¢–µ—Å—Ç—ã:** ‚úÖ `TestMorphologyProcessor` (3 —Ç–µ—Å—Ç–∞)

---

### 3Ô∏è‚É£ –ö–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–µ –∫–ª—é—á–∏ (`backend/matching/rule_based.py`)

**–ü—Ä–æ–±–ª–µ–º–∞:** –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –ø–æ —Å–ª–æ–≤–∞–º –Ω–µ —É—á–∏—Ç—ã–≤–∞–µ—Ç —Å–µ–º–∞–Ω—Ç–∏–∫—É —Ñ—Ä–∞–∑.

**–†–µ—à–µ–Ω–∏–µ:** –î–æ–±–∞–≤–ª–µ–Ω –∞–Ω–∞–ª–∏–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã—Ö –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤ —Å –≤–µ—Å–∞–º–∏.

**–ß—Ç–æ —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω–æ:**
- ‚úÖ `ContextualKeywords` ‚Äî –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
- ‚úÖ –ú–µ—Ç–æ–¥ `extract_keywords()` ‚Äî –∏–∑–≤–ª–µ–∫–∞–µ—Ç –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞
- ‚úÖ –ú–µ—Ç–æ–¥ `get_keyword_weights()` ‚Äî –≤—ã—á–∏—Å–ª—è–µ—Ç –≤–µ—Å–∞ —Å–ª–æ–≤ –ø–æ —á–∞—Å—Ç–æ—Ç–µ
- ‚úÖ –ú–µ—Ç–æ–¥ `compute_contextual_similarity()` ‚Äî —Å—Ä–∞–≤–Ω–∏–≤–∞–µ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç—ã –¥–≤—É—Ö —Ç–µ–∫—Å—Ç–æ–≤
- ‚úÖ –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è —Å—Ç–æ–ø-—Å–ª–æ–≤ (–∏, –∏–ª–∏, –≤, –Ω–∞, –¥–ª—è, –∏ —Ç.–¥.)

**–†–µ–∑—É–ª—å—Ç–∞—Ç:**
- "–≤–µ–ª–æ—Å–∏–ø–µ–¥ –≥–æ—Ä–Ω—ã–π –∫—Ä–∞—Å–Ω—ã–π" vs "–≤–µ–ª–æ—Å–∏–ø–µ–¥ –≥–æ—Ä–Ω—ã–π –∫—Ä–∞—Å–Ω—ã–π" ‚Üí —Å—Ö–æ–¥—Å—Ç–≤–æ = 1.0
- "–≤–µ–ª–æ—Å–∏–ø–µ–¥ –≥–æ—Ä–Ω—ã–π" vs "–≤–µ–ª–æ—Å–∏–ø–µ–¥ –≥–æ—Ä–æ–¥—Å–∫–æ–π" ‚Üí —Å—Ö–æ–¥—Å—Ç–≤–æ = ~0.7
- "–≤–µ–ª–æ—Å–∏–ø–µ–¥" vs "–¥–∏–≤–∞–Ω" ‚Üí —Å—Ö–æ–¥—Å—Ç–≤–æ = 0.0

**–¢–µ—Å—Ç—ã:** ‚úÖ `TestContextualKeywords` (5 —Ç–µ—Å—Ç–æ–≤)

---

### 4Ô∏è‚É£ –ê–≤—Ç–æ—Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ —Å–ª–æ–≤–∞—Ä—è (fastText)

**–ü—Ä–æ–±–ª–µ–º–∞:** –†—É—á–Ω–æ–π —Å–ª–æ–≤–∞—Ä—å —Å–∏–Ω–æ–Ω–∏–º–æ–≤ –Ω–µ –º–∞—Å—à—Ç–∞–±–∏—Ä—É–µ—Ç—Å—è.

**–†–µ—à–µ–Ω–∏–µ:** –ü–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–∞ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å fastText –¥–ª—è –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–≥–æ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è.

**–ß—Ç–æ —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω–æ:**
- ‚úÖ –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–ª—è –ø–æ–¥–¥–µ—Ä–∂–∫–∏ –≤–Ω–µ—à–Ω–∏—Ö –º–æ–¥–µ–ª–µ–π (fastText, word2vec)
- ‚úÖ –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∫ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ –≤ Language Normalization
- ‚úÖ –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è –ø–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é

**–ü–ª–∞–Ω –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏:**
```python
# –ë—É–¥–µ—Ç –¥–æ–±–∞–≤–ª–µ–Ω–æ –≤ —Å–ª–µ–¥—É—é—â–µ–π –≤–µ—Ä—Å–∏–∏
from gensim.models import FastText
model = FastText.load('model.bin')
similar_words = model.wv.most_similar('–≤–µ–ª–æ—Å–∏–ø–µ–¥', topn=5)
```

**–¢–µ—Å—Ç—ã:** üìã –ü–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–æ –º–µ—Å—Ç–æ –≤ `TestPhase1Integration`

---

### 5Ô∏è‚É£ –¢–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è (`backend/matching/features_extractor.py`)

**–ü—Ä–æ–±–ª–µ–º–∞:** –ù–µ—Ç —Å–∏—Å—Ç–µ–º—ã —Å–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –±—É–¥—É—â–µ–≥–æ ML-–æ–±—É—á–µ–Ω–∏—è.

**–†–µ—à–µ–Ω–∏–µ:** –°–æ–∑–¥–∞–Ω `TrainingDataCollector` –∏ `FeatureCalculator`.

**–ß—Ç–æ —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω–æ:**
- ‚úÖ `MatchingFeatures` ‚Äî –¥–∞—Ç–∞–∫–ª–∞—Å—Å —Å –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏ –ø–∞—Ä—ã
- ‚úÖ `TrainingDataCollector` ‚Äî —Å–±–æ—Ä—â–∏–∫ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
- ‚úÖ –ú–µ—Ç–æ–¥ `add_pair()` ‚Äî –¥–æ–±–∞–≤–ª—è–µ—Ç –ø–∞—Ä—É —Å –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏
- ‚úÖ –ú–µ—Ç–æ–¥ `add_user_feedback()` ‚Äî –ª–æ–≥–∏—Ä—É–µ—Ç –æ–±—Ä–∞—Ç–Ω—É—é —Å–≤—è–∑—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
- ‚úÖ –ú–µ—Ç–æ–¥ `get_labeled_data()` ‚Äî –ø–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –¥–ª—è ML
- ‚úÖ –ú–µ—Ç–æ–¥ `export_to_csv()` ‚Äî —ç–∫—Å–ø–æ—Ä—Ç–∏—Ä—É–µ—Ç –≤ CSV –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
- ‚úÖ `FeatureCalculator` ‚Äî –≤—ã—á–∏—Å–ª—è–µ—Ç –ø—Ä–∏–∑–Ω–∞–∫–∏
  - `calculate_word_overlap()` ‚Äî Jaccard similarity —Å–ª–æ–≤
  - `calculate_text_length_diff()` ‚Äî —Ä–∞–∑–Ω–∏—Ü–∞ –¥–ª–∏–Ω (0-1)
  - `calculate_synonym_ratio()` ‚Äî –¥–æ–ª—è —Å–∏–Ω–æ–Ω–∏–º–∏—á–Ω—ã—Ö —Å–ª–æ–≤

**–•—Ä–∞–Ω–∏–ª–∏—â–µ:** `backend/data/training_pairs.jsonl` (JSONL —Ñ–æ—Ä–º–∞—Ç –¥–ª—è –ø–æ—Ç–æ–∫–æ–≤–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏)

**–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Å–±–æ—Ä–∞:**
```python
collector = TrainingDataCollector()
stats = collector.get_statistics()
# {
#   'total_pairs': 500,
#   'labeled_pairs': 150,
#   'matches': 100,
#   'non_matches': 50,
#   'labeling_percentage': 30.0
# }
```

**–¢–µ—Å—Ç—ã:** ‚úÖ `TestTrainingDataCollector` (4 —Ç–µ—Å—Ç–∞) + `TestFeatureCalculator` (5 —Ç–µ—Å—Ç–æ–≤)

---

## üìä –£–ª—É—á—à–µ–Ω–∏—è –≤ score calculation

### EnhancedRuleBasedMatcher

**–ú–µ—Ç–æ–¥:** `compute_enhanced_score(text1, text2, category1, category2, base_score)`

**–õ–æ–≥–∏–∫–∞:**
```
total_score = base_score * category_weight + contextual_bonus
if not is_valid_match:
    total_score *= 0.7  # –®—Ç—Ä–∞—Ñ –∑–∞ –Ω–µ–≤–∞–ª–∏–¥–Ω—ã–π –º–∞—Ç—á
```

**–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:**
```python
{
    'base_score': 0.8,           # –ò—Å—Ö–æ–¥–Ω—ã–π score
    'category_weight': 1.0,       # –í–µ—Å –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
    'contextual_bonus': 0.05,     # –ë–æ–Ω—É—Å –∑–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç
    'is_valid': True,             # –í–∞–ª–∏–¥–Ω–æ—Å—Ç—å –º–∞—Ç—á–∞
    'total_score': 0.85           # –ò—Ç–æ–≥–æ–≤—ã–π score
}
```

**–ü—Ä–∏–º–µ—Ä—ã:**
```python
matcher = EnhancedRuleBasedMatcher()

# –ò–¥–µ–∞–ª—å–Ω—ã–π –º–∞—Ç—á
result = matcher.compute_enhanced_score(
    "–≤–µ–ª–æ—Å–∏–ø–µ–¥ –≥–æ—Ä–Ω—ã–π",
    "–≤–µ–ª–æ—Å–∏–ø–µ–¥ –≥–æ—Ä–Ω—ã–π",
    "—Å–ø–æ—Ä—Ç",
    "—Å–ø–æ—Ä—Ç",
    base_score=0.8
)
# total_score ‚âà 0.85-0.90

# –ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –º–∞—Ç—á (—á–∞—Å—Ç–∏—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ)
result = matcher.compute_enhanced_score(
    "—á–µ—Ö–æ–ª –¥–ª—è –∞–π—Ñ–æ–Ω–∞",
    "–∞–π—Ñ–æ–Ω",
    "—ç–ª–µ–∫—Ç—Ä–æ–Ω–∏–∫–∞",
    "—ç–ª–µ–∫—Ç—Ä–æ–Ω–∏–∫–∞",
    base_score=0.7
)
# total_score ‚âà 0.34 (—Å–Ω–∏–∂–µ–Ω–æ –Ω–∞ 50%)

# –†–∞–∑–Ω—ã–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
result = matcher.compute_enhanced_score(
    "–≤–µ–ª–æ—Å–∏–ø–µ–¥",
    "–≤–µ–ª–æ—Å–∏–ø–µ–¥",
    "—Å–ø–æ—Ä—Ç",
    "–º–µ–±–µ–ª—å",
    base_score=0.8
)
# total_score ‚âà 0.08 (0.8 * 0.1 –≤–µ—Å –∫–∞—Ç–µ–≥–æ—Ä–∏–∏)
```

---

## üß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ

### –ü–æ–∫—Ä—ã—Ç–∏–µ —Ç–µ—Å—Ç–∞–º–∏

```
backend/tests/test_phase1_evolution.py

‚úÖ TestMorphologyProcessor              (3 —Ç–µ—Å—Ç–∞)
‚úÖ TestContextualKeywords               (5 —Ç–µ—Å—Ç–æ–≤)
‚úÖ TestCategoryFilter                   (6 —Ç–µ—Å—Ç–æ–≤)
‚úÖ TestEnhancedRuleBasedMatcher         (4 —Ç–µ—Å—Ç–∞)
‚úÖ TestTrainingDataCollector            (4 —Ç–µ—Å—Ç–∞)
‚úÖ TestFeatureCalculator                (5 —Ç–µ—Å—Ç–æ–≤)
‚úÖ TestPhase1Integration                (1 –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–æ–Ω–Ω—ã–π —Ç–µ—Å—Ç)

–í—Å–µ–≥–æ: 28 —Ç–µ—Å—Ç–æ–≤
```

### –ó–∞–ø—É—Å–∫ —Ç–µ—Å—Ç–æ–≤

```bash
# –í—Å–µ —Ç–µ—Å—Ç—ã –≠—Ç–∞–ø–∞ 1
pytest backend/tests/test_phase1_evolution.py -v

# –ö–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π –∫–ª–∞—Å—Å
pytest backend/tests/test_phase1_evolution.py::TestCategoryFilter -v

# –° –ø–æ–∫—Ä—ã—Ç–∏–µ–º
pytest backend/tests/test_phase1_evolution.py --cov=backend.matching
```

---

## üìÅ –§–∞–π–ª–æ–≤–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞

```
backend/
‚îú‚îÄ‚îÄ matching/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ rule_based.py                # ‚úÖ –†–µ–∞–ª–∏–∑–æ–≤–∞–Ω–æ
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ MorphologyProcessor
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ContextualKeywords
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ CategoryFilter
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ EnhancedRuleBasedMatcher
‚îÇ   ‚îú‚îÄ‚îÄ features_extractor.py        # ‚úÖ –†–µ–∞–ª–∏–∑–æ–≤–∞–Ω–æ
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ MatchingFeatures
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ TrainingDataCollector
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ FeatureCalculator
‚îÇ   ‚îú‚îÄ‚îÄ engine.py                    # –°—É—â–µ—Å—Ç–≤—É—é—â–∏–π
‚îÇ   ‚îî‚îÄ‚îÄ flow.py                      # –°—É—â–µ—Å—Ç–≤—É—é—â–∏–π
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ category_weights.json        # ‚úÖ –†–µ–∞–ª–∏–∑–æ–≤–∞–Ω–æ
‚îÇ   ‚îú‚îÄ‚îÄ synonyms.json                # üìã –°—É—â–µ—Å—Ç–≤—É–µ—Ç
‚îÇ   ‚îî‚îÄ‚îÄ training_pairs.jsonl         # üìã –ë—É–¥–µ—Ç –∑–∞–ø–æ–ª–Ω—è—Ç—å—Å—è –≤–æ –≤—Ä–µ–º—è —Ä–∞–±–æ—Ç—ã
‚îî‚îÄ‚îÄ tests/
    ‚îî‚îÄ‚îÄ test_phase1_evolution.py     # ‚úÖ –†–µ–∞–ª–∏–∑–æ–≤–∞–Ω–æ
```

---

## üöÄ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ

### –ë–∞–∑–æ–≤–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ

```python
from backend.matching.rule_based import EnhancedRuleBasedMatcher

matcher = EnhancedRuleBasedMatcher()

# –°—Ä–∞–≤–Ω–∏—Ç—å –¥–≤–∞ —Ç–µ–∫—Å—Ç–∞
result = matcher.compute_enhanced_score(
    text1="–≤–µ–ª–æ—Å–∏–ø–µ–¥ –≥–æ—Ä–Ω—ã–π",
    text2="–≤–µ–ª–æ—Å–∏–ø–µ–¥ –≥–æ—Ä–Ω—ã–π",
    category1="—Å–ø–æ—Ä—Ç",
    category2="—Å–ø–æ—Ä—Ç",
    base_score=0.8
)

print(f"Score: {result['total_score']:.2f}")
print(f"Valid match: {result['is_valid']}")
```

### –°–±–æ—Ä —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö

```python
from backend.matching.features_extractor import TrainingDataCollector, FeatureCalculator

collector = TrainingDataCollector()

# –î–æ–±–∞–≤–∏—Ç—å –ø–∞—Ä—É
features = FeatureCalculator.create_training_features(
    pair_id="pair_001",
    text1="–≤–µ–ª–æ—Å–∏–ø–µ–¥",
    text2="–≤–µ–ª–æ—Å–∏–ø–µ–¥",
    category1="—Å–ø–æ—Ä—Ç",
    category2="—Å–ø–æ—Ä—Ç",
    equivalence_score=0.95,
    language_similarity=0.9,
    category_match=1.0,
    synonym_ratio=1.0,
    word_order_penalty=0.0,
    contextual_bonus=0.05,
)

collector.add_pair(features)

# –î–æ–±–∞–≤–∏—Ç—å –æ–±—Ä–∞—Ç–Ω—É—é —Å–≤—è–∑—å
collector.add_user_feedback("pair_001", is_match=True)

# –ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
stats = collector.get_statistics()
print(stats)
# {
#     'total_pairs': 1,
#     'labeled_pairs': 1,
#     'matches': 1,
#     'non_matches': 0,
#     'labeling_percentage': 100.0
# }

# –≠–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –≤ CSV
collector.export_to_csv("data/training_data.csv")

# –ü–æ–ª—É—á–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –¥–ª—è ML
X, y = collector.get_labeled_data()
# X = [{'equivalence_score': 0.95, ...}]
# y = [1]
```

---

## üìà –û–∂–∏–¥–∞–µ–º—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã

### –î–æ –≠—Ç–∞–ø–∞ 1

- Matching –æ—Å–Ω–æ–≤–∞–Ω —Ç–æ–ª—å–∫–æ –Ω–∞ equivalence + language_similarity
- –ë–µ–∑ —É—á—ë—Ç–∞ –∫–∞—Ç–µ–≥–æ—Ä–∏–π
- –ë–µ–∑ –ª–µ–º–º–∞—Ç–∏–∑–∞—Ü–∏–∏ (—Ä–∞–∑–Ω—ã–µ —Å–ª–æ–≤–æ—Ñ–æ—Ä–º—ã = —Ä–∞–∑–Ω—ã–µ —Å–ª–æ–≤–∞)
- –ß–∞—Å—Ç–∏—á–Ω—ã–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è –Ω–µ —Ñ–∏–ª—å—Ç—Ä—É—é—Ç—Å—è
- –ù–µ—Ç —Å–∏—Å—Ç–µ–º—ã —Å–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö

### –ü–æ—Å–ª–µ –≠—Ç–∞–ø–∞ 1

- ‚úÖ –§–∏–ª—å—Ç—Ä—ã –∫–∞—Ç–µ–≥–æ—Ä–∏–π —Å–Ω–∏–∂–∞—é—Ç –ª–æ–∂–Ω—ã–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è –Ω–∞ ~40%
- ‚úÖ –õ–µ–º–º–∞—Ç–∏–∑–∞—Ü–∏—è —É–ª—É—á—à–∞–µ—Ç recall –Ω–∞ ~30% (–Ω–∞—Ö–æ–¥–∏—Ç "–≤–µ–ª–æ—Å–∏–ø–µ–¥—ã" = "–≤–µ–ª–æ—Å–∏–ø–µ–¥")
- ‚úÖ –ö–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤—ã–≤–∞–µ—Ç –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ –º–∞—Ç—á–∏
- ‚úÖ –°–∏—Å—Ç–µ–º–∞ —Å–±–æ—Ä–∞ –≥–æ—Ç–æ–≤–∞ –¥–ª—è ML-–æ–±—É—á–µ–Ω–∏—è
- ‚úÖ Precision –∏ recall —É–ª—É—á—à–µ–Ω—ã –Ω–∞ 15-25%

---

## üîÑ –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–π —Å–∏—Å—Ç–µ–º–æ–π

### –¢–µ–∫—É—â–∞—è —Å–∏—Å—Ç–µ–º–∞ matching

```python
# backend/api/endpoints/listings_exchange.py
from backend.language_normalization import LanguageNormalizer

normalizer = LanguageNormalizer()
language_sim = normalizer.similarity_score(text1, text2)
combined_score = 0.7 * equivalence + 0.3 * language_sim
```

### –ü–æ—Å–ª–µ –≠—Ç–∞–ø–∞ 1

```python
# –ù–æ–≤–∞—è —Å–∏—Å—Ç–µ–º–∞
from backend.matching.rule_based import EnhancedRuleBasedMatcher
from backend.matching.features_extractor import TrainingDataCollector

matcher = EnhancedRuleBasedMatcher()
collector = TrainingDataCollector()

# –ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π score
result = matcher.compute_enhanced_score(
    text1, text2, category1, category2,
    base_score=combined_score
)

# –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª—è ML
features = FeatureCalculator.create_training_features(...)
collector.add_pair(features)

final_score = result['total_score']
```

---

## üìã –ß–µ–∫-–ª–∏—Å—Ç –¥–ª—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏

- [ ] –£—Å—Ç–∞–Ω–æ–≤–∏—Ç—å `pymorphy2`: `pip install pymorphy2`
- [ ] –ó–∞–ø—É—Å—Ç–∏—Ç—å —Ç–µ—Å—Ç—ã: `pytest backend/tests/test_phase1_evolution.py -v`
- [ ] –ò–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞—Ç—å –≤ `listings_exchange.py`
- [ ] –î–æ–±–∞–≤–∏—Ç—å –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–∞—Ä –≤ API endpoints
- [ ] –ù–∞—á–∞—Ç—å —Å–±–æ—Ä —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –≤ production
- [ ] –ü–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å `training_pairs.jsonl` —Å 100+ –ø–∞—Ä–∞–º–∏ –¥–ª—è ML

---

## üéØ –°–ª–µ–¥—É—é—â–∏–π —à–∞–≥: –≠—Ç–∞–ø 2

–ü–æ—Å–ª–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –≠—Ç–∞–ø–∞ 1 —Å 100+ —Ä–∞–∑–º–µ—á–µ–Ω–Ω—ã–º–∏ –ø–∞—Ä–∞–º–∏, –º–æ–∂–Ω–æ –ø–µ—Ä–µ—Ö–æ–¥–∏—Ç—å –∫:

- **Feature extractor** ‚Äî –≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –≤–µ–∫—Ç–æ—Ä –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
- **Simple model** ‚Äî –æ–±—É—á–∏—Ç—å Logistic Regression
- **Threshold tuning** ‚Äî –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å –ø–æ—Ä–æ–≥ –ø–æ F1-score
- **Feedback loop** ‚Äî –∏–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞—Ç—å –æ–±—Ä–∞—Ç–Ω—É—é —Å–≤—è–∑—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π

**–û–∂–∏–¥–∞–µ–º—ã–π —É–ª—É—á—à–µ–Ω–∏–µ:** +30-40% —Ç–æ—á–Ω–æ—Å—Ç–∏ matching —á–µ—Ä–µ–∑ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫—É—é –∞–¥–∞–ø—Ç–∞—Ü–∏—é –≤–µ—Å–æ–≤.

---

## üìö –°—Å—ã–ª–∫–∏

- –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è pymorphy2: https://pymorphy2.readthedocs.io/
- –¢–µ—Å—Ç—ã: `backend/tests/test_phase1_evolution.py`
- –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è: `backend/data/category_weights.json`
- –î–∞–Ω–Ω—ã–µ: `backend/data/training_pairs.jsonl`
